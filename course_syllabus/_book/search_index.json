[
["index.html", "Data Analysis and Visualization using R 1 Resources, Exercises and Presentations", " Data Analysis and Visualization using R Michiel Noback, PhD last edit: 2018-05-15 1 Resources, Exercises and Presentations Resources, Exercises and Presentations Data &amp; Resources Course Data In this section all data files used or required for the course presentations or exercises are listed. Whale selenium data: whale_selenium.txt Bird observation data: Observations-Data-2014.xlsx or, as csv Food constituents: food_constituents.txt Wine review data: winemag-data-130k-v2.csv Resources These resources will be used extensively during the course. The R project The official R language website: www.r-project.org CRAN The Comprehensive R Archive Network (CRAN) is a network of ftp and web servers around the world that store identical, up-to-date, versions of code and documentation for R R studio R studio is the most popular IDE for writing, running, documenting, and maintaining R code projects: http://www.rstudio.com R Markdown R Markdown is a Markdown “Dialect” used for presenting, documenting and reporting in R: http://rmarkdown.rstudio.com R cheat sheet The R cheat sheet that is also available at the computer exam. RMarkdown reference The RMarkdown reference cards with extensive documentation. Also available at the computer exam! Swirl course Swirl course to accompany this course: http://github.com/MichielNoback/R_Data_Analysis Bioconductor Bioconductor provides tools for the analysis and comprehension of high- throughput genomic data: http://www.bioconductor.org Exercises To work on the exercises, download the Rmarkdown file (right click: save as..) and open it in Rstudio. Work on the Exercises and klick “Knit HTML” to generate an HTML report of your work. For your convenience, I also provide a link to the Knitted PDF version. Swirl The swirl course to accompany the lectures and exercises Course assignments Course assignments part 1 | Rmd | PDF | Course assignments part 2 | Rmd | PDF | Course assignments part 1 Solutions | HTML | PDF | Course assignments part 2 Solutions | HTML | PDF | Training exam Training exam zip file Download the zip, extract it and start working on the file training TRAINING_EXAM.Rmd (pdf view also supplied). Do not use the internet, but only the supplied files and time yourself to a maximum of 1,5 hours. The actual test will be slightly longer (2 hours). Solutions are supplied but I suggest you only look at these after completing the test. Training exam zip file alternative link Screencasts Setting up on a Windows system Youtube Starting with Rstudio Youtube Presentations Introduction: Toolbox | HTML | PDF | This is the general introduction of the course. It gives a brief overview of the tools in the R toolbox: The programming language R The Integrated Development Environment (IDE) RStudio) RMarkdown, the technology to create well-formatted documents with embedded R code and its output SWIRL, the interactive learning environment for R Basic R | HTML | PDF | The basic datatypes and functionality of R are explored, as well as some plotting techniques: scatter plot, histogram, and boxplot. Complex Datatypes | HTML | PDF | You will get to know the more complex of the R data types: factor (actually a base data type, but complex in its use) list which is the type that can hold any type of any length dataframe, the mother of all datatypes, which is actually also a list albeit a special one. You will see how to create them and manipulate them on a basic level. This section also shows a sunny day scenario for reading data from file. Functions | HTML | PDF | Functions are explored here. Functions are reusable pieces of code. In this presentation, a variety of funcion-related aspects of R are presented: Descriptive statistics functions Sorting and ordering General purpose functions (e.g.. paste, str, cut) Advanced usage of read.table() Writing data to file Flow control Creating functions Dataframe manipulations | HTML | PDF | Here, all functions and techniques used fo manipulating dataframes (and lists) are discussed. These include with to create a local scope/environment subset to make advanced and readable selections apply and its relatives lapply, sapply, tapply aggregate split and merge Sampling and testing | HTML | PDF | Some remaining topics are reviewed here: Random sampling of a distribution, a predefined set, or range of numbers Statistitcal tests (t.test, aov, chisq.test) "],
["usecases.html", "2 Example Use Cases", " 2 Example Use Cases In this chapter, some example use cases will be presented demonstrating some concept or function. The topics for these use cases are selected because they appear to be harder to comprehend for my students, are a bit out of scope for the lectures, or because they are simply too extensive to fit into a few slides of a presentation. "],
["dfselection.html", "2.1 Dataframe Selections", " 2.1 Dataframe Selections R offers a wealth of methods to make selection on dataframes by columns, rows, or both. We’ll explore the iris dataset, a dataframe holding morphological data on several species of plants from the genus Iris: DT::datatable(iris) There are only three species in this dataset table(iris$Species) ## ## setosa versicolor virginica ## 50 50 50 but how do they relate to each other with repect to Sepal length? with(iris, boxplot(Sepal.Length ~ Species, ylab = &quot;Sepal length (cm)&quot;, xlab = &quot;Iris species&quot;)) Now suppose I want to get the data from virginica plants that have a Sepal length smaller than the largest Sepal length of setosa plants? First of course we’ll need the maximum of the setosa plants: max.setosa &lt;- max(iris[iris$Species == &quot;setosa&quot;, &quot;Sepal.Length&quot;]) max.setosa ## [1] 5.8 Which plant is it? Let’s use the subset function to find out. subset(x = iris, subset = (Species == &quot;setosa&quot; &amp; Sepal.Length == max.setosa)) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 15 5.8 4 1.2 0.2 setosa Now filter out the virginica plants that have a Sepal length smaller than this value. I’ll show two approaches, one with logical indexing and one with subset ##get a logical for small plants logi.small.sepal &lt;- iris$Sepal.Length &lt; max.setosa logi.small.sepal ## [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [12] TRUE TRUE TRUE FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [23] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [34] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [45] TRUE TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE TRUE FALSE ## [56] TRUE FALSE TRUE FALSE TRUE TRUE FALSE FALSE FALSE TRUE FALSE ## [67] TRUE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [78] FALSE FALSE TRUE TRUE TRUE FALSE FALSE TRUE FALSE FALSE FALSE ## [89] TRUE TRUE TRUE FALSE FALSE TRUE TRUE TRUE TRUE FALSE TRUE ## [100] TRUE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE ## [111] FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [122] TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [144] FALSE FALSE FALSE FALSE FALSE FALSE FALSE ##get a logical for virginica plants logi.virginica &lt;- iris$Species == &quot;virginica&quot; logi.virginica ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [23] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [34] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [45] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [56] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [67] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [78] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [89] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [100] FALSE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [111] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [122] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [133] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE ## [144] TRUE TRUE TRUE TRUE TRUE TRUE TRUE ##combine the two via a boolean operation logi.both &lt;- logi.small.sepal &amp; logi.virginica logi.both ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [12] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [23] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [34] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [45] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [56] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [67] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [78] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [89] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [100] FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE ## [111] FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [122] TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [133] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [144] FALSE FALSE FALSE FALSE FALSE FALSE FALSE ##use it as a selector on the rows of the iris DF iris[logi.both, ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 107 4.9 2.5 4.5 1.7 virginica ## 114 5.7 2.5 5.0 2.0 virginica ## 122 5.6 2.8 4.9 2.0 virginica Of course, you will usually perform this selection in one statement, but the operations carried out by R will be exactly the same (but without creating any variables of course): iris[iris$Sepal.Length &lt; max.setosa &amp; iris$Species == &quot;virginica&quot;, ] ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 107 4.9 2.5 4.5 1.7 virginica ## 114 5.7 2.5 5.0 2.0 virginica ## 122 5.6 2.8 4.9 2.0 virginica The function subset will do the same behind the scenes, but your code may be more to your liking: subset(x = iris, subset = Sepal.Length &lt; max.setosa &amp; Species == &quot;virginica&quot;) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 107 4.9 2.5 4.5 1.7 virginica ## 114 5.7 2.5 5.0 2.0 virginica ## 122 5.6 2.8 4.9 2.0 virginica By the way, beware to use only one boolean and: &amp;, not &amp;&amp;. This will not give an error but only an empty result set subset(x = iris, subset = Sepal.Length &lt; max.setosa &amp;&amp; Species == &quot;virginica&quot;) ## [1] Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;0 rows&gt; (or 0-length row.names) &amp; and &amp;&amp; indicate logical AND and | and || indicate logical OR. The shorter form performs elementwise comparisons in much the same way as arithmetic operators. The longer form evaluates left to right examining only the first element of each vector. Evaluation proceeds only until the result is determined. The longer form is appropriate for programming control-flow and typically preferred in if clauses. Can you figure out why using &amp;&amp; would give an empty set in the above case? See The R manual for details. "],
["apply.html", "2.2 Apply", " 2.2 Apply Consider the women dataset, holding height and weight of a population sample of 15 women: DT::datatable(women, options = list(&quot;pageLength&quot; = 15), colnames = c(&quot;Woman&quot;, names(women))) To calculate the average height and the average weight of this sample, one could of course simply do with(women, { print(mean(height)) print(mean(weight)) }) ## [1] 65 ## [1] 136.7333 However, when your dataset has (a lot) more columns, repeating this will be quite tedious…unless you use a for loop for (i in 1:length(women)) { print(mean(women[,i])) } ## [1] 65 ## [1] 136.7333 Enter apply(), a very nice function to do this in a handy one-liner apply(X = women, MARGIN = 2, FUN = mean) ## height weight ## 65.0000 136.7333 The arguments I supplied to applyhave the following purpose: X = women specifies the data to be processed MARGIN = 2 specifies wether columns or rows shoud be processed; 1 = rows and 2 = columns FUN = mean speciefies the function to be applied to the given dataframe Not only gives apply the the exact same result (of course, duh), but this approach has several advantages: apply returns a named vector where the elements are named the same as the corresponding columns of the original dataframe apply is computationally more efficient than the other approaches it requires less code; a good programmer types as little as possible - except for Java programmers of course :-) If you really have strongh feelings about typing no more than strictly required, you can of course also omit the method parameters: apply(women, 2, mean) ## height weight ## 65.0000 136.7333 But if you are just starting out with R, I suggest you invest those few character strokes for readability later on. The above example dealt with columns. For instance, if you want to calculate the BMI of these women, you’ll need to target the rows. The BMI formula is \\[weight/height^2*703\\] where weight is in pounds and height is in inches. This formula is implemented in the following function. bmi &lt;- function(height, weight) { (weight / height^2) * 703 } bmi(65, 150) ## [1] 24.95858 You can also apply the formula to the women dataset: women$bmi1 &lt;- apply( X = women, MARGIN = 1, FUN = function(x){(x[2] / x[1]^2) * 703}) head(women, n = 4) ## height weight bmi1 ## 1 58 115 24.03240 ## 2 59 117 23.62856 ## 3 60 120 23.43333 ## 4 61 123 23.23811 if you like to use your own formula (it’s always a good idea to write logic only once and reuse it in different places), you’ll still need to wrap it inside an anonymous function call: women$bmi2 &lt;- apply( X = women, MARGIN = 1, FUN = function(x){bmi(x[1], x[2])}) head(women, n = 4) ## height weight bmi1 bmi2 ## 1 58 115 24.03240 24.03240 ## 2 59 117 23.62856 23.62856 ## 3 60 120 23.43333 23.43333 ## 4 61 123 23.23811 23.23811 "],
["embeddeddf.html", "2.3 Processing Embedded Dataframes", " 2.3 Processing Embedded Dataframes Suppose you have imported some data that has a structure like this genes &lt;- c(&quot;gene A&quot;, &quot;gene B&quot;, &quot;gene C&quot;, &quot;gene D&quot;) positions &lt;- c(&quot;chr01:128757:129667&quot;, &quot;chr01:366389:486990&quot;, &quot;chr02:8986463:9100856&quot;, &quot;chr03:53536:87201&quot;) my.genome &lt;- data.frame(gene = genes, position = positions) my.genome ## gene position ## 1 gene A chr01:128757:129667 ## 2 gene B chr01:366389:486990 ## 3 gene C chr02:8986463:9100856 ## 4 gene D chr03:53536:87201 The problem here is that the second column, positions, of type character, actually holds three different variables: the chromosome identifyer, the start position and the stop position on the chromosome. To be able to perform analyses of chromosomal contents, or positional contexts, we will need to split this column into separate columns, each holding exactly one variable of the correct type (factor, integer and integer). When I first encountered this type of problem (it is a challenge actually, some teachers would object, not a problem…), my first thought was “easy, simply apply a split and bind as three columns”. Let’s have a look at how the strsplit function works in splitting strings strsplit(x = positions[1:2], split = &quot;:&quot;) ## [[1]] ## [1] &quot;chr01&quot; &quot;128757&quot; &quot;129667&quot; ## ## [[2]] ## [1] &quot;chr01&quot; &quot;366389&quot; &quot;486990&quot; As you can see, strsplit generates a list of vectors, with each vector corresponding to the string at the same index of the original character vector. So, easy, I thought. Simply assign these elements to three new columns of the original dataframe (assuming every split character results in a vector of three). I first created the columns, defined my splitter function and then used apply to get the job done ## create columns my.genome[, c(&quot;chromosome&quot;, &quot;start&quot;, &quot;stop&quot;)] &lt;- NA ## define splitter function loc.splitter &lt;- function(x) { ## strsplit returns a list! strsplit(x[&quot;position&quot;], &quot;:&quot;)[[1]] } ## use apply to fill the columns my.genome[, 3:5] &lt;- apply(X = my.genome, MARGIN = 1, FUN = loc.splitter) my.genome ## gene position chromosome start stop ## 1 gene A chr01:128757:129667 chr01 366389 9100856 ## 2 gene B chr01:366389:486990 128757 486990 chr03 ## 3 gene C chr02:8986463:9100856 129667 chr02 53536 ## 4 gene D chr03:53536:87201 chr01 8986463 87201 Whoa, what happened here?! This was not what I had in mind. Can you figure out what happened? … I did figure it out (eventually…). The applied function returned three elements at a time, and I had apply fill three columns of my dataframe. And that is exactly what R did, fill the three columns, but not by row but by column! Have a look at the output from apply and you can see: apply(X = my.genome, MARGIN = 1, FUN = loc.splitter) ## [,1] [,2] [,3] [,4] ## [1,] &quot;chr01&quot; &quot;chr01&quot; &quot;chr02&quot; &quot;chr03&quot; ## [2,] &quot;128757&quot; &quot;366389&quot; &quot;8986463&quot; &quot;53536&quot; ## [3,] &quot;129667&quot; &quot;486990&quot; &quot;9100856&quot; &quot;87201&quot; Fortunately, R has a function to transpose this kind of structure (a matrix actually): the t() function, so that is what I did: my.genome[, 3:5] &lt;- t(apply(X = my.genome, MARGIN = 1, FUN = loc.splitter)) my.genome ## gene position chromosome start stop ## 1 gene A chr01:128757:129667 chr01 128757 129667 ## 2 gene B chr01:366389:486990 chr01 366389 486990 ## 3 gene C chr02:8986463:9100856 chr02 8986463 9100856 ## 4 gene D chr03:53536:87201 chr03 53536 87201 Yeah, that’s what I’m talking about! (Feeling very happy with myself…until I googled this problem). I found out there are a gazillion solutions to this problem, but only one of them is very very simple, because it uses a function you know really well: read.table, but not with the file = argument but with text =: my.genome &lt;- data.frame(gene = genes, position = positions) my.genome &lt;- cbind( my.genome, read.table( text = as.character(my.genome$position), sep = &quot;:&quot;)) colnames(my.genome) &lt;- c(colnames(my.genome)[1:2], &quot;chr&quot;, &quot;start&quot;, &quot;stop&quot;) my.genome ## gene position chr start stop ## 1 gene A chr01:128757:129667 chr01 128757 129667 ## 2 gene B chr01:366389:486990 chr01 366389 486990 ## 3 gene C chr02:8986463:9100856 chr02 8986463 9100856 ## 4 gene D chr03:53536:87201 chr03 53536 87201 That’s it. The lessons learned here: Always know that GIYF (Google Is Your Friend) When reading tables, also those embedded within others, use read.table You really learn a lot by fiddling about with data "],
["ttest.html", "2.4 Applying statistical tests on Dataframes", " 2.4 Applying statistical tests on Dataframes 2.4.1 Intro The t-test (or Student’s t-test) is one of the most used statistical tests. It can help determine whether the means of two samples are differing significantly. This form is the two-sample t-test. In its alternative form, you can compare a single sample to an expected (population) mean (one-sample t-test). An important assumption of the test is that the data follow a normal (Gaussian) distribution (that is why the t-test is one of the parametric tests). If this is not the case (or if you simply don’t want to test for or assume normality), you can use the non-parametric t-test counterpart, the Mann-Whitney U Test. If more that two groups are involved, ANOVA is your go-to guy. To investigate the application of these statistical tests on dataframes, we’ll use the built-in dataset called PlantGrowth. This dataset shows the yield of a certain plant species under three different conditions (control and two treatments). My initial scientific question is “Is there a difference between the yields under these different conditions?”. My null hypothesis H0 would therefore be “There is no difference in yield”. 2.4.2 Data exploration Of course, you always visually inspect your data before embarking on a statistical-testing quest: with(PlantGrowth, boxplot(weight ~ group)) This plot indicates that the distributions of ctrl and trt1 are quite close, and that trt2 differs from the others. The t-test and ANOVA assume normality. Normality can be roughly assessed from boxplots (as in the figure above - do you know how?), but histograms and density curves are better suited for this purpose. Let’s create a histogram. hist(PlantGrowth$weight, prob=TRUE, main = NA, xlab=&quot;Yield (g dry weight)&quot;) That looks pretty “normal” doesn’t it? Adding a real normal curve usually helps a lot: x &lt;- seq(0,20,0.005) m &lt;- mean(PlantGrowth$weight) weight.sd &lt;- sd(PlantGrowth$weight) hist(PlantGrowth$weight, prob=TRUE, main = NA, xlab=&quot;Yield (g dry weight)&quot;) lines(x, dnorm(x, mean=m, sd=weight.sd), col=&quot;darkred&quot;, lwd=2) Alternatively, you can plot the density curve of the data and add the normal distribution. plot(density(PlantGrowth$weight), main = NA, ylim = c(0, 0.6)) lines(x, dnorm(x, mean=m, sd=weight.sd), col=&quot;darkred&quot;, lwd=2) OK, conclusion: it looks like a normal distribution, albeit not a perfect one. Let’s proceed for now. 2.4.3 The t-test Since t-tests are designed for comparing at most 2 groups, we’ll compare the two groups that are most alike in yield distribution: ctrl and trt1. test.result &lt;- t.test(x = PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;], y = PlantGrowth$weight[PlantGrowth$group == &quot;trt1&quot;]) test.result ## ## Welch Two Sample t-test ## ## data: PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;] and PlantGrowth$weight[PlantGrowth$group == &quot;trt1&quot;] ## t = 1.1913, df = 16.524, p-value = 0.2504 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.2875162 1.0295162 ## sample estimates: ## mean of x mean of y ## 5.032 4.661 It’s as simple as that! To extract the p-value (or any other attribute), use the dollar operator: test.result$p.value test.result$conf.int ## [1] 0.2503825 ## [1] -0.2875162 1.0295162 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 As you can see, the p-value is 0.250, well above the usual cutoff of 5% (0.05). Therefore, we can conclude that the yields do not differ significantly between the control and treatment 1 plants (and accept the null hypothesis). Comparing control versus treatment 2 gives test.result2 &lt;- t.test(x = PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;], y = PlantGrowth$weight[PlantGrowth$group == &quot;trt2&quot;]) test.result2 ## ## Welch Two Sample t-test ## ## data: PlantGrowth$weight[PlantGrowth$group == &quot;ctrl&quot;] and PlantGrowth$weight[PlantGrowth$group == &quot;trt2&quot;] ## t = -2.134, df = 16.786, p-value = 0.0479 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.98287213 -0.00512787 ## sample estimates: ## mean of x mean of y ## 5.032 5.526 And this p-value indicates there may be a statistically relevant effect of treatment 2 (p-value = 0.0478993, just below the 5% cutoff). Now, let’s extend this to the situation where you want to apply a t-test over the rows of a dataframe, for example when you have a dataframe holding expression values of genes (rows) in two groups of samples (columns). Here is a very simple dataframe to explore this scenario. Columns a through d represent measurements for condition A (e.g. the control group) and e through h condition B (e.g. treatment with a novel drug). gene.expr &lt;- data.frame(a = c(20, 34, 24, 51), b = c(21, 32, 27, 45), c = c(17, 26, 21, 49), d = c(18, 28, 28, 53), e = c(22, 33, 29, 44), f = c(16, 34, 26, 42), g = c(19, 31, 31, 41), h = c(20, 28, 30, 43)) rownames(gene.expr) &lt;- c(&quot;SRSSHT&quot;, &quot;GeNPL-1&quot;, &quot;DUNNO&quot;, &quot;WHTVR&quot;) controls &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) treatment &lt;- c(&quot;e&quot;, &quot;f&quot;, &quot;g&quot;, &quot;h&quot;) ##have a look gene.expr ## a b c d e f g h ## SRSSHT 20 21 17 18 22 16 19 20 ## GeNPL-1 34 32 26 28 33 34 31 28 ## DUNNO 24 27 21 28 29 26 31 30 ## WHTVR 51 45 49 53 44 42 41 43 I am only interested in the p-value to be able to select the most interesting genes. Here is a custom function to extract this from a row of my dataframe. my.t.test &lt;- function(x){ t.test(x[controls], x[treatment])$p.value } and now the t-test applied over the rows apply(X = gene.expr, MARGIN = 1, FUN = my.t.test) ## SRSSHT GeNPL-1 DUNNO WHTVR ## 0.87746477 0.53288953 0.08786967 0.02001060 As you can see, only one gene in this example meets the standard 95% p value cutoff: WHTVR. (NB: of course, no multiple testing corrections has been applied here - that is out of scope for this use case). 2.4.4 ANOVA The technique (one-way) Analysis of Variance (ANOVA) is an extension of the two-sample t test for independent groups covering situations where there are more than two groups being compared. In one-way ANOVA the data is sub-divided into groups based on a single classification factor. Before an ANOVA can be carried out, it has to be determined that the variances for all factors are equal. You cann do this using the bartlett.test function: with(PlantGrowth, bartlett.test(weight ~ group)) ## ## Bartlett test of homogeneity of variances ## ## data: weight by group ## Bartlett&#39;s K-squared = 2.8786, df = 2, p-value = 0.2371 From the output we can see that the p-value of 0.2371 is not less than the significance level of 0.05. This means we cannot reject the null hypothesis that the variance is the same for all treatment groups. This means that there is no evidence to suggest that the variance in plant growth is different for the three treatment groups. In this example, we will analyse all three groups of the PlantGrowth dataset together. To investigate the differences between these groups, we fit the one-way ANOVA model using the lm function: yield.lm &lt;- lm(weight ~ group, data = PlantGrowth) Then, using the summary function, have a look at the parameter estimates and standard errors for the treatment effects: summary(yield.lm) ## ## Call: ## lm(formula = weight ~ group, data = PlantGrowth) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.0710 -0.4180 -0.0060 0.2627 1.3690 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.0320 0.1971 25.527 &lt;2e-16 *** ## grouptrt1 -0.3710 0.2788 -1.331 0.1944 ## grouptrt2 0.4940 0.2788 1.772 0.0877 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.6234 on 27 degrees of freedom ## Multiple R-squared: 0.2641, Adjusted R-squared: 0.2096 ## F-statistic: 4.846 on 2 and 27 DF, p-value: 0.01591 The model output indicates some evidence of a difference in the average growth for the 2nd treatment compared to the control group. An analysis of variance (ANOVA) table for this model can be produced via the anova command (passing the linear model object): anova(yield.lm) ## Analysis of Variance Table ## ## Response: weight ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## group 2 3.7663 1.8832 4.8461 0.01591 * ## Residuals 27 10.4921 0.3886 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This table confirms that there are differences between the groups which were highlighted in the model summary. The function confint is used to calculate confidence intervals on the treatment parameters, by default 95% confidence intervals: confint(yield.lm) ## 2.5 % 97.5 % ## (Intercept) 4.62752600 5.4364740 ## grouptrt1 -0.94301261 0.2010126 ## grouptrt2 -0.07801261 1.0660126 The model residuals can be plotted against the fitted values to investigate the model assumptions. First we create a data frame with the fitted values, residuals and treatment identifiers: plant.mod = data.frame(Fitted = fitted(yield.lm), Residuals = resid(yield.lm), Treatment = PlantGrowth$group) and then produce the plot: library(ggplot2) ggplot(plant.mod, aes(Fitted, Residuals, colour = Treatment)) + geom_point() We can see that there is no major problem with the diagnostic plot but some evidence of different variabilities in the spread of the residuals for the three treatment groups. ALTERNATIVELY, WE COULD HAVE DONE THIS: 1: fit a model fit &lt;- aov(weight ~ group, data=PlantGrowth) fit ## Call: ## aov(formula = weight ~ group, data = PlantGrowth) ## ## Terms: ## group Residuals ## Sum of Squares 3.76634 10.49209 ## Deg. of Freedom 2 27 ## ## Residual standard error: 0.6233746 ## Estimated effects may be unbalanced 2: diagnostic plots Diagnostic plots provide checks for heteroscedasticity, normality, and influential observerations. layout(matrix(c(1,2,3,4),2,2)) # optional layout plot(fit) 3: evaluate model effects summary(fit) # display Type I ANOVA table ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## group 2 3.766 1.8832 4.846 0.0159 * ## Residuals 27 10.492 0.3886 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 drop1(fit, ~ . , test=&quot;F&quot;) # type III SS and F Tests ## Single term deletions ## ## Model: ## weight ~ group ## Df Sum of Sq RSS AIC F value Pr(&gt;F) ## &lt;none&gt; 10.492 -25.517 ## group 2 3.7663 14.258 -20.316 4.8461 0.01591 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Now suppose we want to apply this to a dataframe of gene expression values, as shown before in the example of the t-test, but now with three instead of two groups: gene.expr2 &lt;- data.frame(a = c(20, 34, 24, 51), b = c(21, 32, 27, 45), c = c(17, 26, 21, 49), d = c(18, 28, 28, 53), e = c(22, 33, 29, 44), f = c(16, 34, 26, 42), g = c(19, 31, 31, 41), h = c(20, 28, 30, 43), i = c(20, 32, 22, 50), j = c(18, 33, 21, 52), k = c(21, 29, 19, 51), l = c(22, 27, 23, 54)) rownames(gene.expr2) &lt;- c(&quot;SRSSHT&quot;, &quot;GeNPL-1&quot;, &quot;DUNNO&quot;, &quot;WHTVR&quot;) controls &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;) treatment1 &lt;- c(&quot;e&quot;, &quot;f&quot;, &quot;g&quot;, &quot;h&quot;) treatment2 &lt;- c(&quot;i&quot;, &quot;j&quot;, &quot;k&quot;, &quot;l&quot;) ##have a look gene.expr2 ## a b c d e f g h i j k l ## SRSSHT 20 21 17 18 22 16 19 20 20 18 21 22 ## GeNPL-1 34 32 26 28 33 34 31 28 32 33 29 27 ## DUNNO 24 27 21 28 29 26 31 30 22 21 19 23 ## WHTVR 51 45 49 53 44 42 41 43 50 52 51 54 We need to apply anova to each row and extract the p-value. First, we need the custom function to apply with: my.anova &lt;- function(x) { #define factor gr.factor &lt;- factor(rep(x = c(&quot;control&quot;, &quot;treatment1&quot;, &quot;treatment2&quot;), each = 4)) #perform anova my.oav &lt;- aov(formula = expr ~ group, data = data.frame(expr = x, group = gr.factor)) #return p-value summary(my.oav)[[1]]$&#39;Pr(&gt;F)&#39;[1] } Now, it’s a simple apply call again: apply(X = gene.expr2, MARGIN = 1, FUN = my.anova) ## SRSSHT GeNPL-1 DUNNO WHTVR ## 0.6692884795 0.7638487821 0.0047833839 0.0008448382 These results indicate a significant effect in genes DUNNO and WHTVR (again, without having applied multiple testing correction!). The next step would be to investigate the effect size (if anything significant has been found). This can be carried out using Tukeys HSD. "],
["lines-helpers-regression-lines-loess-and-density-lines-curves.html", "2.5 Lines: Helpers, Regression lines, Loess and Density Lines &amp; Curves", " 2.5 Lines: Helpers, Regression lines, Loess and Density Lines &amp; Curves 2.5.1 Drawing curves from functions Sometimes you don’t have data to plot but only a function, for instance a simple polynomial function. \\[f(x)=x^{3}+3x^{2}-6x-8\\] (Example lent from http://rpubs.com/wkmor1/simple-derivatives-in-r) A simple plot of this function can be obtained using curve: f &lt;- function(x) x^3 + 3 * x^2 - 6 * x - 8 curve(f, -5, 4, ylab=&quot;f(x)&quot;) You are often interested in a derivative of a function. Here is one for f(x): #Define a new function without body g &lt;- function(x) {} #assign as body the derivative of f(x) body(g) &lt;- D(body(f), &#39;x&#39;) #see what it looks like curve(g, -5, 4) So what does this derivative look like? body(g) ## 3 * x^2 + 3 * (2 * x) - 6 Now wouldn’t it be nice to add a line of the derivative of this function in the same plot? Easy peasy! The trick is using par(new=TRUE). While we’re at it, let’s add some key points to the ploit as well (requires library rootSolve - use install.packages(&quot;rootSolve&quot;)) library(rootSolve) roots &lt;- multiroot(g, c(-5, 4)) roots$root ## [1] -2.7320508 0.7320508 f(roots$root) ## [1] 10.3923 -10.3923 #adjust Margins for secondary axis par(mar = c(5,5,2,5)) curve(f, -5, 4, col=&quot;green&quot;, lwd=2) points(f(roots$root) ~ roots$root, col=&quot;green&quot;, lwd=2) par(new=TRUE) curve(g, -5, 4, col=&quot;blue&quot;, xlab=NA, ylab=NA, axes=F, lwd=2) axis(side=4) mtext(side=4, line=3, &quot;Derivative of f(x)&quot;) library(sm) ## Package &#39;sm&#39;, version 2.2-5.4: type help(sm) for summary information with(mtcars, { cyl.f &lt;- factor(cyl, levels = c(4, 6, 8), labels = c(&quot;4 cylinder&quot;, &quot;6 cylinder&quot;, &quot;8 cylinder&quot;)) sm.density.compare(mpg, cyl, xlab = &quot;Miles per Gallon&quot;) title(main = &quot;MPG distribution by Car Cylinders&quot;) colfill &lt;- c(2:(1+length(levels(cyl.f)))) legend(&quot;topleft&quot;, levels(cyl.f), fill = colfill) }) "]
]
